#############################################################################
# Pipeline for read mapping simulations with varying divergence
#############################################################################

import os
import re
import treeparse as tp

#############################################################################
# Example cmd for mouse genome

# Need to first run the cactus-preprocess script to generate commands and cactus config files:
# cactus-prepare genomes.txt --outDir turtle-output --outSeqFile turtle-output/turtles.txt --outHal turtle-output/turtles.hal --jobStore jobstore --gpu --defaultCores 32

# Run snakemake
# snakemake -p -s cactus_gpu.smk --dryrun

# To generate rulegraph image:
# snakemake -p -s mapping_sims.smk --configfile simulation-configs/mm39.yaml --profile profiles/slurm_profile/ --dryrun --rulegraph | dot -Tpng > dag.png

# /n/holylfs05/LABS/informatics/Users/gthomas/turtles/cactus

#############################################################################

# Cactus works via a post-order transversal of the input tree and runs several steps at each node of the tree.
# For tip nodes Cactus runs its preprocess command which masks the input fasta for each genome
#   1. Preprocess (mask)
#       Inputs: Original genome fasta
#       Output: Masked genome fasta with same basename as input fasta, but in the Cactus output directory
#
# For each internal node, cactus runs 3 commands:
#   2. Blast
#       Inputs: The fasta sequences of the descendant nodes. For a tip this is the one from step 1, for an internal node
#               this is the result of step 4
#       Output: A .cigar file
#
#   3. Align
#       Inputs: The .cigar file from the previous step and the fasta sequences of the descendant nodes. 
#               For a tip this is the one from step 1, for an internal node this is the result of step 4 
#       Output: A .hal file
#               
#   4. Convert (hal2fasta)
#       Inputs: The .hal file from the previous step
#       Output: A fasta file for the current node
#

#############################################################################
# System setup

debug = False;

wd = "/n/holylfs05/LABS/informatics/Users/gthomas/turtles/cactus/";
os.chdir(wd);
print(os.getcwd());
# Switching to the working directory of the project so paths can be relative

TMPDIR = config["tmp_dir"];
# A directory with lots of space to use for temporary files generated by the cactus-align command

CACTUS_PATH = "singularity exec --nv --cleanenv " + config["cactus_path"];
CACTUS_PATH_TMP = "singularity exec --nv --cleanenv --bind " + TMPDIR + ":/tmp " + config["cactus_path"];
# The path to the cactus executable with and without a tmpdir binding
# Must be gpu enabled for now

#############################################################################
# Input files and output paths

INPUT_FILE = config["input_file"];
# The cactus input file used to generate the config file with cactus-prepare

OUTPUT_DIR = config["output_dir"];
# The output directory specified when cactus-prepare was run

CACTUS_FILE = os.path.join(OUTPUT_DIR, os.path.basename(INPUT_FILE));
CONFIG_FILE = os.path.join(OUTPUT_DIR, "config-prepared.xml");
# The config files genearated from cactus-prepare
# config: XML config file probably read by some of the sub-programs...
# output: lists the sequence files expected as output for all nodes in the tree

#job_path = os.path.join(OUTPUT_DIR, "jobstore");
# The temporary/job directory specified in cactus-prepare

# final_hal_file = "turtles.hal";
# The final hal file generated on the root node -- currently still encoded as Anc00.hal

#############################################################################
# Reading files

tips = {};
# The main dictionary hold information and file paths for tips in the tree:
# [output fasta file from mask step] : { 'input' : "original genome fasta file", 'name' : "genome name in tree", 'output' : "expected output from mask step (same as key)" }

first = True;
for line in open(INPUT_FILE):
    if first:
        #tree = line.strip();
        first = False;
        continue;
    # The first line contains the input tree... skip

    line = line.strip().split("\t");
    cur_base = os.path.basename(line[1]);
    tips[cur_base] = { 'input' : [line[1]], 'name' : line[0], 'output' : "NA" };
## Read the genome names and original genome fasta file paths from the same cactus input file used with cactus-prepare

if debug:
    for g in tips:
        print(g, tips[g]);
    print("===================================================================================");


####################

internals = {};
# The main dictionary hold information and file paths for internal nodes in the tree:
# [node name] : { 'name' : "node name in tree", 'blast-inputs' : [the expected inputs for the blast step], 'align-inputs' : [the expected inputs for the align step],
#                   'hal-inputs' : [the expected inputs for the hal2fasta step], 'blast-output' : "the .cigar file output from the blast step",
#                   'align-output' : "the .hal file output from the align step", 'hal-output' : "the fasta file output from the hal2fasta step" }

first = True;
for line in open(CACTUS_FILE):
    if first:
        anc_tree = line.strip();
        first = False;
        continue;
    # The first line contains the tree with internal nodes labeled... save this for later

    line = line.strip().split("\t");
    cur_base = os.path.basename(line[1]);

    if cur_base in tips:
        tips[cur_base]['output'] = cur_base;
    else:
        internals[line[0]] = {  'name' : line[0], 
                                'desc-seqs' : "NA", 
                                'hal-file' : [cur_base.replace(".fa", ".hal")], 
                                'cigar-file' : cur_base.replace(".fa", ".cigar"), 
                                'seq-file' : cur_base };
## Read the internal node labels and output file paths from the file generated by cactus-prepare

####################

tinfo, anc_tree, root = tp.treeParse(anc_tree);
internal_nodes = [ n for n in tinfo if tinfo[n][2] != 'tip' ];
root_name = tinfo[root][3];
## Parse the tree with the internal node labels

####################

for node in internal_nodes:
    name = tinfo[node][3];
    # The cactus node label

    cur_desc = tp.getDesc(node, tinfo);
    # Get descendant nodes for the current node

    expected_seq_inputs = [];
    for desc in cur_desc:
        if tinfo[desc][2] == 'tip':
            expected_seq_inputs.append([ desc_key for desc_key in tips if tips[desc_key]['name'] == desc ][0]);
        else:
            expected_seq_inputs.append([ desc_key for desc_key in internals if internals[desc_key]['name'] == tinfo[desc][3] ][0] + ".fa");
    internals[name]['desc-seqs'] = expected_seq_inputs;
        # Get fasta file names from each descendant node and add them to the dict for this node        
## Get information about descendant nodes from the parsed tree

if debug:
    for g in internals:
        print(g, internals[g]);
    print("===================================================================================");
    sys.exit("debug ok");

#############################################################################
# Final rule - rule that depends on final expected output file and initiates all
# the other rules

localrules: all

rule all:
    input:
        expand(os.path.join(OUTPUT_DIR, "{final_tip}"), final_tip=[out for out in tips]),
        expand(os.path.join(OUTPUT_DIR, "{internal_node}.fa"), internal_node=[node for node in internals])

# #############################################################################
# # Pipeline rules

rule mask:
    input:
        lambda wildcards: tips[wildcards.final_tip]['input']
    output:
        os.path.join(OUTPUT_DIR, "{final_tip}")
    params:
        path = CACTUS_PATH,
        input_file = INPUT_FILE,
        config_file = os.path.join(OUTPUT_DIR, CONFIG_FILE),
        cactus_file = os.path.join(OUTPUT_DIR, CACTUS_FILE),
        genome_name = lambda wildcards: tips[wildcards.final_tip]['name'],
        job_dir = lambda wildcards: os.path.join(TMPDIR, tips[wildcards.final_tip]['name'] + "-mask")
    resources:
        partition = "gpu",
        gpu = 2,
        cpus = 64,
        mem = "100g",
        time = "2:00:00"
    run:
        if os.path.isdir(params.job_dir):
            shell("{params.path} cactus-preprocess {params.job_dir} {params.input_file} {params.cactus_file} --inputNames {params.genome_name} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --gpu --restart")
        else:
            shell("{params.path} cactus-preprocess {params.job_dir} {params.input_file} {params.cactus_file} --inputNames {params.genome_name} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --gpu")
        # When not requesting all CPU on a node: toil.batchSystems.abstractBatchSystem.InsufficientSystemResources: The job LastzRepeatMaskJob is requesting 64.0 cores, more than the maximum of 32 cores that SingleMachineBatchSystem was configured with, or enforced by --maxCores.Scale is set to 1.0.


####################

rule blast:
    input:
        lambda wildcards: [ os.path.join(OUTPUT_DIR, input_file) for input_file in internals[wildcards.internal_node]['desc-seqs'] ]
    output:
        os.path.join(OUTPUT_DIR, "{internal_node}.cigar")
    params:
        path = CACTUS_PATH,
        config_file = os.path.join(OUTPUT_DIR, CONFIG_FILE),
        cactus_file = os.path.join(OUTPUT_DIR, CACTUS_FILE),
        node = lambda wildcards: wildcards.internal_node,
        job_dir = lambda wildcards: os.path.join(TMPDIR, wildcards.internal_node + "-blast")
    resources:
        partition = "gpu",
        gpu = 4,
        cpus = 64,
        mem = "100g",
        time = "48:00:00"
    run:
        if os.path.isdir(params.job_dir):
            shell("{params.path} cactus-blast {params.job_dir} {params.cactus_file} {output} --root {params.node} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --gpu --restart")
        else:
            shell("{params.path} cactus-blast {params.job_dir} {params.cactus_file} {output} --root {params.node} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --gpu")


####################

rule align:
    input:
        cigar_file = os.path.join(OUTPUT_DIR, "{internal_node}.cigar"),
        #seq_files = lambda wildcards: [ os.path.join(OUTPUT_DIR, input_file) for input_file in internals[wildcards.internal_node]['desc-seqs'] ]
    output:
        os.path.join(OUTPUT_DIR, "{internal_node}.hal")
    params:
        path = CACTUS_PATH_TMP,
        config_file = os.path.join(OUTPUT_DIR, CONFIG_FILE),
        cactus_file = os.path.join(OUTPUT_DIR, CACTUS_FILE),
        node = lambda wildcards: wildcards.internal_node,
        job_dir = lambda wildcards: os.path.join(TMPDIR, wildcards.internal_node + "-align"),
    resources:
        partition = "bigmem",
        cpus = 64,
        mem = "400g",
        time = "48:00:00"
    run:
        if os.path.isdir(params.job_dir):
            shell("{params.path} cactus-align {params.job_dir} {params.cactus_file} {input.cigar_file} {output} --root {params.node} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --restart")
        else:
            shell("{params.path} cactus-align {params.job_dir} {params.cactus_file} {input.cigar_file} {output} --root {params.node} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus}")

####################

rule convert:
    input:
        os.path.join(OUTPUT_DIR, "{internal_node}.hal")
        #lambda wildcards: [ os.path.join(output_dir, input_file) for input_file in internals[wildcards.internal_node]['hal-inputs'] ][0]
    output:
        os.path.join(OUTPUT_DIR, "{internal_node}.fa")
    params:
        path = CACTUS_PATH,
        node = lambda wildcards: wildcards.internal_node,
    resources:
        partition = "shared",
        cpus = 8,
        mem = "12g",
        time = "4:00:00"
    shell:
        """
        {params.path} hal2fasta {input} {params.node} --hdf5InMemory > {output}
        """

#############################################################################
#############################################################################
#############################################################################


# node_rounds = { 0 : ["08", "12", "13", "14", "16", "18", "19", "20"], 
#                 1 : ["06", "07", "11", "15", "17"], 
#                 2 : ["03", "09", "10"], 
#                 3 : ["04", "05"], 
#                 4 : ["01", "02"], 
#                 5 : ["00"] };
# The number of rounds of cactus alignment and the ancestral node labels parsed in each round
# Nodes should be output from cactus-prepare in postorder so nodes in each round can be run in parallel
## TODO: Parse from cactus-prepare output

# def get_inputs(wildcards):
#     print(wildcards.final, genomes[wildcards.final]['input']);
#     print(wildcards.final)
#     print(genomes[wildcards.final]['node-type']);
#     # if genomes[wildcards.final]['node-type'] == "tip":
#     #     print(main_config_file);
#     #     return os.path.join("turtle-output-smk", "config-prepared.xml");
#     # else:
#     print([ os.path.join(output_dir, d_out) for d_out in genomes[wildcards.final]['input'] ]);
#     print("----------");
#     return [ os.path.join(output_dir, d_out) for d_out in genomes[wildcards.final]['input'] ];
# def get_node_name(wildcards):
#     #print(1)
#     #print(wildcards.final, genomes_test[wildcards.final]['name']);
#     return genomes[wildcards.final]['name']
# def get_job_dir(wildcards):
#     #print(2)
#     #print(wildcards.final, genomes[wildcards.final]['name']);
#     #print("----------");
#     return os.path.join("jobstore", "Anc" + genomes[wildcards.final]['name'] + "-blast");
# def get_node_type(wildcards):
#     #print(3)
#     #print(wildcards.final, genomes[wildcards.final]['node-type']);
#     return genomes[wildcards.final]['node-type']    

# rule blast:
#     input:
#         #lambda wildcards: [ os.path.join(output_dir, "{0}".format(d_out)) for d_out in genomes[wildcards.final] ]
#         #get_inputs
#         lambda wildcards: [ os.path.join(output_dir, d_out) for d_out in genomes[wildcards.final]['input'] ]
#     output:
#         os.path.join(output_dir, "{final}")
#     params:
#         path = cactus_path,
#         #node = lambda wildcards: genomes_test[wildcards.final]['name'],
#         node = lambda wildcards: tips[wildcards.final]['name'],
#         #job_dir = lambda wildcards: os.path.join("jobstore", "Anc" + genomes_test[wildcards.final]['name'] + "-blast"),
#         job_dir = lambda wildcards: os.path.join("jobstore", "Anc" + internals[wildcards.final]['name'] + "-blast"),
#         pre_output_file = os.path.join(output_dir, main_output_file),
#         config_file = os.path.join(output_dir, main_config_file),
#         node_type = lambda wildcards: genomes[wildcards.final]['node-type']  
#     resources:
#         partition = "gpu",
#         gpu = 4,
#         cpus = 64,
#         mem = "100g",
#         time = "48:00:00"
#     run:
#         if params.node_type == "tip":
#             shell("{params.path} cactus-preprocess {params.job_dir} {params.genome_file} {params.pre_output_file} --inputNames {params.genome_name} --realTimeLogging --logInfo --retryCount 0 --configFile {input.config_file} --maxCores {resources.cpus} --gpu")
#         else:
#             shell("{params.path} cactus-blast {params.job_dir} {params.pre_output_file} {output} --root {params.node} --realTimeLogging --logInfo --retryCount 0 --configFile {params.config_file} --maxCores {resources.cpus} --gpu")

#############################################################################